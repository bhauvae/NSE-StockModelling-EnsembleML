{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-19T18:59:45.131675400Z",
     "start_time": "2023-09-19T18:59:42.543683900Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import talib\n",
    "from sklearn import utils\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import Pattern\n",
    "from collections import Counter\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import model_selection\n",
    "from collections import Counter\n",
    "\n",
    "import talib as tb\n",
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import yfinance as yf\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "['CDL2CROWS',\n 'CDL3BLACKCROWS',\n 'CDL3INSIDE',\n 'CDL3LINESTRIKE',\n 'CDL3OUTSIDE',\n 'CDL3STARSINSOUTH',\n 'CDL3WHITESOLDIERS',\n 'CDLABANDONEDBABY',\n 'CDLADVANCEBLOCK',\n 'CDLBELTHOLD',\n 'CDLBREAKAWAY',\n 'CDLCLOSINGMARUBOZU',\n 'CDLCONCEALBABYSWALL',\n 'CDLCOUNTERATTACK',\n 'CDLDARKCLOUDCOVER',\n 'CDLDOJI',\n 'CDLDOJISTAR',\n 'CDLDRAGONFLYDOJI',\n 'CDLENGULFING',\n 'CDLEVENINGDOJISTAR',\n 'CDLEVENINGSTAR',\n 'CDLGAPSIDESIDEWHITE',\n 'CDLGRAVESTONEDOJI',\n 'CDLHAMMER',\n 'CDLHANGINGMAN',\n 'CDLHARAMI',\n 'CDLHARAMICROSS',\n 'CDLHIGHWAVE',\n 'CDLHIKKAKE',\n 'CDLHIKKAKEMOD',\n 'CDLHOMINGPIGEON',\n 'CDLIDENTICAL3CROWS',\n 'CDLINNECK',\n 'CDLINVERTEDHAMMER',\n 'CDLKICKING',\n 'CDLKICKINGBYLENGTH',\n 'CDLLADDERBOTTOM',\n 'CDLLONGLEGGEDDOJI',\n 'CDLLONGLINE',\n 'CDLMARUBOZU',\n 'CDLMATCHINGLOW',\n 'CDLMATHOLD',\n 'CDLMORNINGDOJISTAR',\n 'CDLMORNINGSTAR',\n 'CDLONNECK',\n 'CDLPIERCING',\n 'CDLRICKSHAWMAN',\n 'CDLRISEFALL3METHODS',\n 'CDLSEPARATINGLINES',\n 'CDLSHOOTINGSTAR',\n 'CDLSHORTLINE',\n 'CDLSPINNINGTOP',\n 'CDLSTALLEDPATTERN',\n 'CDLSTICKSANDWICH',\n 'CDLTAKURI',\n 'CDLTASUKIGAP',\n 'CDLTHRUSTING',\n 'CDLTRISTAR',\n 'CDLUNIQUE3RIVER',\n 'CDLUPSIDEGAP2CROWS',\n 'CDLXSIDEGAP3METHODS']"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb.get_function_groups()['Pattern Recognition']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T19:00:59.604047400Z",
     "start_time": "2023-09-19T19:00:59.582643300Z"
    }
   },
   "id": "bfb386654371ccdb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_signals(data):\n",
    "    \"\"\"\n",
    "    Creates technical trading signals based on candlestick charting patterns.\n",
    "\n",
    "    Args:\n",
    "        data (pandas.DataFrame): A dataframe of OHLCV (Open, High, Low, Close, Volume) data.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A dataframe of OHLCV data with additional columns for each signal generated.\n",
    "    \"\"\"\n",
    "\n",
    "    for signal in cs_patterns_rest:\n",
    "        try:\n",
    "            values = cs_patterns_rest[signal](\n",
    "                data.Open, data.High, data.Low, data.Close)\n",
    "            data[signal] = values\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "    data = data.reset_index()\n",
    "    \n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "699c08d85267cff3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_names = [\"svm\", \"knn\", \"rf\", \"gb\", \"xgb_model\"]\n",
    "\n",
    "def format_data(df, start_time, end_time,custom=True,trigrams=True,patterns=True, avg_days=5, additional=[\"O\", \"M\", \"V\"]):\n",
    "    \"\"\"Takes input features and creates TA indicators, the 8-trigram scheme and Target labels.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df: \n",
    "        Pandas DataFrame containing Open, High, Low, Close, Volume and Date columns.\n",
    "    start_time: \n",
    "        Start time in datetime format when the stock is purchased\n",
    "    end_time: \n",
    "        End time in datetime format when the stock is sold\n",
    "    custom: \n",
    "        Boolean Value to specify whether to create custom signals or not\n",
    "    trigrams: \n",
    "        Boolean value to specify whether to calculate 8 Trigrams or not\n",
    "    patterns: \n",
    "        Boolean Value to specify whether to calculate typical candlestick patterns or not\n",
    "    avg_days: \n",
    "        Integer denoting the number of days for which rolling average has to be calculated\n",
    "    additional: \n",
    "        List containing values O,M,V which specify which additional stock market indicators are to be calculated\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    Pandas DataFrame with columns - \n",
    "        Updated Open, High, Low and Closing Prices, Volume, Trigrams, Target and optionally Short Line Cdl, Long Line Cdl, Spinning Top and Closing Marubozu (if custom signals are required)\n",
    "    \"\"\"\n",
    "    \n",
    "    date_mask = (df[\"Date\"] > start_time) & (df[\"Date\"] <= end_time)\n",
    "    df = df.loc[date_mask]\n",
    "\n",
    "    short_ind = 5\n",
    "    long_ind = 10\n",
    "\n",
    "\n",
    "    # OVERLAP INDICATORS\n",
    "    df[\"ma\"] = tb.MA(df[\"Close\"], timeperiod=short_ind)\n",
    "    df[\"ema\"] = tb.EMA(df[\"Close\"], timeperiod=long_ind)\n",
    "    df[\"dema\"] = tb.DEMA(df[\"Close\"], timeperiod=short_ind)\n",
    "    df[\"kama\"] = tb.KAMA(df[\"Close\"], timeperiod=short_ind)\n",
    "    df[\"sma\"] = tb.SMA(df[\"Close\"], timeperiod=long_ind)\n",
    "    df[\"sar\"] = tb.SAR(df[\"High\"], df[\"Low\"])\n",
    "\n",
    "    # MOMENTUM INDICATORS\n",
    "    df[\"adx\"] = tb.ADX(df[\"High\"], df[\"Low\"],\n",
    "                       df[\"Close\"], timeperiod=long_ind)\n",
    "    df[\"cci\"] = tb.CCI(df[\"High\"], df[\"Low\"],\n",
    "                       df[\"Close\"], timeperiod=long_ind)\n",
    "    df[\"apo\"] = tb.APO(df[\"Close\"], fastperiod=long_ind,\n",
    "                       slowperiod=short_ind)\n",
    "    df[\"bop\"] = tb.BOP(df[\"Open\"], df[\"High\"], df[\"Low\"], df[\"Close\"])\n",
    "    df[\"macd\"], df[\"macdsignal\"], df[\"macdhist\"] = tb.MACD(\n",
    "        df[\"Close\"], fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "    df[\"mfi\"] = tb.MFI(df[\"High\"], df[\"Low\"], df[\"Close\"],\n",
    "                       df[\"Volume\"], timeperiod=long_ind)\n",
    "    df[\"mom\"] = tb.MOM(df[\"Close\"], timeperiod=long_ind)\n",
    "    df[\"rsi\"] = tb.RSI(df[\"Close\"], timeperiod=long_ind)\n",
    "\n",
    "    # VOLUME INDICATORS\n",
    "    df[\"ad\"] = tb.AD(df[\"High\"], df[\"Low\"], df[\"Close\"], df[\"Volume\"])\n",
    "    df[\"adosc\"] = tb.ADOSC(df[\"High\"], df[\"Low\"], df[\"Close\"],\n",
    "                           df[\"Volume\"], fastperiod=short_ind, slowperiod=long_ind)\n",
    "    df[\"obv\"] = tb.OBV(df[\"Close\"], df[\"Volume\"])\n",
    "    df[\"trange\"] = tb.TRANGE(df[\"High\"], df[\"Low\"], df[\"Close\"])\n",
    "    df[\"atr\"] = tb.ATR(df[\"High\"], df[\"Low\"],\n",
    "                       df[\"Close\"], timeperiod=long_ind)\n",
    "    df[\"natr\"] = tb.NATR(df[\"High\"], df[\"Low\"],\n",
    "                         df[\"Close\"], timeperiod=long_ind)\n",
    "\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # 8 TRIGRAMS\n",
    "    if trigrams == True:\n",
    "        trigrams = []\n",
    "        for i in range(1, len(df)):\n",
    "            if (df.loc[i, \"High\"] > df.loc[i-1, \"High\"]) & (df.loc[i, \"Low\"] < df.loc[i-1, \"Low\"]) & (df.loc[i, \"Close\"] > df.loc[i-1, \"Close\"]):\n",
    "                signal = 100  # \"BullishHorn\"\n",
    "            elif (df.loc[i, \"High\"] > df.loc[i-1, \"High\"]) & (df.loc[i, \"Low\"] < df.loc[i-1, \"Low\"]) & (df.loc[i, \"Close\"] < df.loc[i-1, \"Close\"]):\n",
    "                signal = -100  # \"BearHorn\"\n",
    "            elif (df.loc[i, \"High\"] > df.loc[i-1, \"High\"]) & (df.loc[i, \"Low\"] > df.loc[i-1, \"Low\"]) & (df.loc[i, \"Close\"] > df.loc[i-1, \"Close\"]):\n",
    "                signal = 100  # \"BullishHigh\"\n",
    "            elif (df.loc[i, \"High\"] > df.loc[i-1, \"High\"]) & (df.loc[i, \"Low\"] > df.loc[i-1, \"Low\"]) & (df.loc[i, \"Close\"] < df.loc[i-1, \"Close\"]):\n",
    "                signal = -100  # \"BearHigh\"\n",
    "            elif (df.loc[i, \"High\"] < df.loc[i-1, \"High\"]) & (df.loc[i, \"Low\"] < df.loc[i-1, \"Low\"]) & (df.loc[i, \"Close\"] > df.loc[i-1, \"Close\"]):\n",
    "                signal = 100  # \"BullishLow\"\n",
    "            elif (df.loc[i, \"High\"] < df.loc[i-1, \"High\"]) & (df.loc[i, \"Low\"] < df.loc[i-1, \"Low\"]) & (df.loc[i, \"Close\"] < df.loc[i-1, \"Close\"]):\n",
    "                signal = -100  # \"BearLow\"\n",
    "            elif (df.loc[i, \"High\"] < df.loc[i-1, \"High\"]) & (df.loc[i, \"Low\"] > df.loc[i-1, \"Low\"]) & (df.loc[i, \"Close\"] > df.loc[i-1, \"Close\"]):\n",
    "                signal = 100  # \"BullishHarami\"\n",
    "            elif (df.loc[i, \"High\"] < df.loc[i-1, \"High\"]) & (df.loc[i, \"Low\"] > df.loc[i-1, \"Low\"]) & (df.loc[i, \"Close\"] < df.loc[i-1, \"Close\"]):\n",
    "                signal = -100  # \"BearHarami\"\n",
    "            else:\n",
    "                signal = 0\n",
    "            trigrams.append(signal)\n",
    "    else:\n",
    "        trigrams = [0]*(len(df.index)-1)\n",
    "        \n",
    "    df.drop(df.index[0], inplace=True)\n",
    "    df[\"trigrams\"] = trigrams\n",
    "\n",
    "\n",
    "    # TARGET\n",
    "    df[\"target\"] = df[\"Close\"].pct_change().rolling(\n",
    "        avg_days).mean().shift(avg_days)\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    columns = [\"Open\", \"High\", \"Volume\", \"Low\",\n",
    "               \"trigrams\", \"target\"]\n",
    "        \n",
    "    # if custom == True:\n",
    "    #     df = create_signals(data=df)\n",
    "    #     columns = columns + [\"shortLineCdl\",\n",
    "    #                          \"longLineCdl\", \"spinningTop\", \"closingMarubozu\"]\n",
    "\n",
    "    if \"O\" in additional:\n",
    "        columns = columns + [\"ma\", \"ema\", \"dema\", \"kama\", \"sma\", \"sar\"]\n",
    "    if \"M\" in additional:\n",
    "        columns = columns + [\"adx\", \"cci\", \"apo\",\n",
    "                             \"bop\", \"macd\", \"mfi\", \"mom\", \"rsi\"]\n",
    "    if \"V\" in additional:\n",
    "        columns = columns + [\"ad\", \"adosc\", \"obv\", \"trange\", \"atr\", \"natr\"]\n",
    "\n",
    "    df = df[columns]\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "209b3039b230d2de"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "def fit_models(sample, models, cv=0, classes=2,fit=False):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function used to fit models and evaluate their performance on a given dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sample: pandas dataframe\n",
    "        Pandas dataframe with the necessary features \n",
    "    models: list\n",
    "        List of ML models \n",
    "    cv: int \n",
    "        Number of cross validations\n",
    "    classes: int\n",
    "        Number of target classes\n",
    "    fit: Bool \n",
    "        Flag to indicate if the model has to be fitted or not \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    fitted_models : list\n",
    "        List of fitted ML models\n",
    "    X_test : year\n",
    "        A feature matrix for Test set \n",
    "    y_test : year\n",
    "        Labels for Test set\n",
    "    \"\"\"\n",
    "    \n",
    "        \n",
    "    ITER_SIZE = 5\n",
    "    _df = pd.DataFrame()\n",
    "\n",
    "    for col in sample.columns:\n",
    "\n",
    "        _df[col] = sample[col]\n",
    "        for i in range(ITER_SIZE):\n",
    "            _df[f\"{col}_{i}\"] = sample[col].shift(periods=i+1)\n",
    "            if _df.shape[0] > 8000:\n",
    "                raise Exception(\"Weird stuff going on\")\n",
    "        _df = _df.merge(_df, how=\"right\")\n",
    "    sample = _df\n",
    "\n",
    "    X = sample.dropna().drop([\"target\"], axis=1)\n",
    "    X = X.dropna().drop([f\"target_{i}\" for i in range(ITER_SIZE)], axis=1)\n",
    "    \n",
    "    sample.dropna(inplace=True)\n",
    "    y = sample[\n",
    "        \"target\"].shift(-1).apply(lambda x: create_target(x,classes=classes,st_dev=sample[\"target\"].std()))\n",
    "        \n",
    "    scaler = StandardScaler()\n",
    "    pipeline = Pipeline(steps=[(\"scaler\", scaler), ])\n",
    "    X = pipeline.fit_transform(X)\n",
    "    \n",
    "    split_size = int(len(X) * 0.8)\n",
    "    X_train, y_train = X[:split_size], y[:split_size]\n",
    "    X_test, y_test = X[split_size:], y[split_size:]\n",
    "    \n",
    "    y_train = np.stack(y_train.values.tolist(), axis=0)\n",
    "    y_test = np.stack(y_test.values.tolist(), axis=0)\n",
    "    X_train = np.asarray(X_train).astype(np.float32)\n",
    "    y_train = np.asarray(y_train).astype(np.float32)\n",
    "    X_test = np.asarray(X_test).astype(np.float32)\n",
    "    y_test = np.asarray(y_test).astype(np.float32)\n",
    "    X_train_lstm = X_train.reshape(X_train.shape[0], -1, ITER_SIZE+1)\n",
    "    X_test_lstm = X_test.reshape(X_test.shape[0], -1, ITER_SIZE+1)\n",
    "    if fit == True:\n",
    "        fitted_models = []\n",
    "        if len(models) == 0:\n",
    "\n",
    "            svm_params = {\n",
    "                \"svc__C\": [1],\n",
    "                \"svc__gamma\": [0.1]\n",
    "            }\n",
    "            knn_params = {\n",
    "                \"knn__n_neighbors\": [150],\n",
    "                \"knn__weights\": [\"distance\"],\n",
    "                \"knn__algorithm\": [\"auto\"],\n",
    "                \"knn__leaf_size\": [1]\n",
    "\n",
    "            }\n",
    "            rf_params = {\n",
    "                \"rf__n_estimators\": [9],\n",
    "                \"rf__criterion\": [\"gini\"],\n",
    "                \"rf__min_samples_leaf\": [5],\n",
    "                \"rf__max_depth\": [1]\n",
    "            }\n",
    "            gb_params = {\n",
    "                \"gb__n_estimators\": [1],\n",
    "                \"gb__max_features\": [7],\n",
    "                \"gb__max_depth\": [1]\n",
    "            }\n",
    "            xgb_params = {\n",
    "                \"xgb__n_estimators\": [10],\n",
    "\n",
    "                \"xgb__max_depth\": [3],\n",
    "                \"xgb__min_child_weight\": [10],\n",
    "                \"xgb__gamma\": [0],\n",
    "                \"xgb__learning_rate\": [0.1],\n",
    "                \"xgb__seed\": [27],\n",
    "                \"xgb__subsample\": [0.65],\n",
    "            }\n",
    "\n",
    "            print(\"\\tFitting Models...\")\n",
    "          \n",
    "            svm, svm_best_params = iterate_models(\n",
    "                SVC(), X_train, y_train, svm_params, cv)\n",
    "\n",
    "            knn, knn_best_params = iterate_models(KNeighborsClassifier(), X_train,\n",
    "                                                y_train, knn_params, cv)\n",
    "\n",
    "            rf, rf_best_params = iterate_models(RandomForestClassifier(),\n",
    "                                                X_train, y_train, rf_params, cv)\n",
    "\n",
    "            gb, gb_best_params = iterate_models(GradientBoostingClassifier(),\n",
    "                                                X_train, y_train, gb_params, cv)\n",
    "            xgb_model, xgb_best_params = iterate_models(xgb.XGBClassifier(),\n",
    "                                                        X_train, y_train, xgb_params, cv)\n",
    "            if cv != 0:\n",
    "                print(\"SVM: \")\n",
    "                print(svm_best_params)\n",
    "                print(\"KNN: \")\n",
    "                print(knn_best_params)\n",
    "                print(\"RF: \")\n",
    "                print(rf_best_params)\n",
    "                print(\"GB: \")\n",
    "                print(gb_best_params)\n",
    "                print(\"XGB: \")\n",
    "                print(xgb_best_params)\n",
    "\n",
    "            fitted_models = [svm, knn, rf, gb, xgb_model]\n",
    "\n",
    "        else:\n",
    "            for i, model in enumerate(models):\n",
    "                print(f\"\\tFitting Model_{model_names[i]}\")\n",
    "                if i == 5:\n",
    "                    model.fit(X_train_lstm, y_train)\n",
    "                else:\n",
    "                    model.fit(X_train, y_train)\n",
    "                fitted_models.append(model)\n",
    "                filename = model_names[i]+\".sav\"\n",
    "                pickle.dump(model, open(\n",
    "                f\"Lin_et_al_2021//ensemble_models//{classes}class//\"+filename, 'wb'))\n",
    "    else:\n",
    "        fitted_models = [joblib.load(f\"Lin_et_al_2021//ensemble_models//{classes}class//\"+model) for model in os.listdir(f\"Lin_et_al_2021//ensemble_models//{classes}class//\")]\n",
    "        \n",
    "    return fitted_models, X_test, y_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T10:08:54.617660800Z",
     "start_time": "2023-09-24T10:08:54.590658900Z"
    }
   },
   "id": "4d649f1b01132fa8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def predict_models(models, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Predicts the target values of a given list of models on a test set\n",
    "    \n",
    "    Args:\n",
    "    models (list): A list of models to be used for prediction.\n",
    "    X_test (numpy array or pandas dataframe): The test set input features.\n",
    "    y_test (numpy array or pandas dataframe): The test set target values.\n",
    "    \n",
    "    Returns:\n",
    "    y_preds (list): A list of target value predictions for each model.\n",
    "    \"\"\"\n",
    "\n",
    "    y_preds = []\n",
    "    for model in models:\n",
    "        try:\n",
    "            y_pred = model.predict(X_test)\n",
    "            y_preds.append(y_pred)\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "            break\n",
    "    return y_preds\n",
    "\n",
    "\n",
    "def score_predictions( models,ticker, X_test,y_test,average):\n",
    "        \"\"\"\n",
    "        Calculates the evaluation metrics for multiple classification models.\n",
    "        \n",
    "        Parameters:\n",
    "        models (list): List of trained models for prediction.\n",
    "        ticker (str): Ticker symbol of the stock.\n",
    "        X_test (array-like): Test dataset of features.\n",
    "        y_test (array-like): Test dataset of target labels.\n",
    "        average (str): Type of averaging to be used for the metrics calculation.\n",
    "        Possible values are: \"micro\", \"macro\" and \"weighted\".\n",
    "        \n",
    "        Returns:\n",
    "        pandas.DataFrame: DataFrame with evaluation metrics for each model.\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "    \n",
    "        pipeline = Pipeline(\n",
    "            steps=[(\"scaler\", scaler)])\n",
    "        X_test = pipeline.fit_transform(X_test)\n",
    "        y_pred = predict_models(models, X_test, y_test\n",
    "        df = pd.DataFrame({\"ticker\": ticker,\n",
    "                        \"svm_acc\": metrics.accuracy_score(y_test, y_pred[0]),\n",
    "                        \"svm_prec\": metrics.precision_score(y_test, y_pred[0], average=average),\n",
    "                        \"svm_recall\": metrics.recall_score(y_test, y_pred[0], average=average),\n",
    "                        \"svm_f1\": metrics.f1_score(y_test, y_pred[0], average=average),\n",
    "                        \"knn_acc\": metrics.accuracy_score(y_test, y_pred[1]),\n",
    "                        \"knn_prec\": metrics.precision_score(y_test, y_pred[1], average=average),\n",
    "                        \"knn_recall\": metrics.recall_score(y_test, y_pred[1], average=average),\n",
    "                        \"knn_f1\": metrics.f1_score(y_test, y_pred[1], average=average),\n",
    "                        \"rf_acc\": metrics.accuracy_score(y_test, y_pred[2]),\n",
    "                        \"rf_prec\": metrics.precision_score(y_test, y_pred[2], average=average),\n",
    "                        \"rf_recall\": metrics.recall_score(y_test, y_pred[2], average=average),\n",
    "                        \"rf_f1\": metrics.f1_score(y_test, y_pred[2], average=average),\n",
    "                        \"gb_acc\": metrics.accuracy_score(y_test, y_pred[3]),\n",
    "                        \"gb_prec\": metrics.precision_score(y_test, y_pred[3], average=average),\n",
    "                        \"gb_recall\": metrics.recall_score(y_test, y_pred[3], average=average),\n",
    "                        \"gb_f1\": metrics.f1_score(y_test, y_pred[3], average=average),\n",
    "                        \"xgb_acc\": metrics.accuracy_score(y_test, y_pred[4]),\n",
    "                        \"xgb_prec\": metrics.precision_score(y_test, y_pred[4], average=average),\n",
    "                        \"xgb_recall\": metrics.recall_score(y_test, y_pred[4], average=average),\n",
    "                        \"xgb_f1\": metrics.f1_score(y_test, y_pred[4], average=average), }, index=[0])\n",
    "       \n",
    "        return df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4275b4430906d52"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def run_simulation(N,START_TIME,END_TIME,AVG_DAYS,TRIGRAMS,ADDITIONAL,CLASSES,symbols):\n",
    "    \"\"\"\n",
    "    Runs a simulation on a subset of stocks using various machine learning models.\n",
    "\n",
    "    Args:\n",
    "    - N (int): the number of stocks to include in the simulation\n",
    "    - START_TIME (str): the start date for the simulation (in YYYY-MM-DD format)\n",
    "    - END_TIME (str): the end date for the simulation (in YYYY-MM-DD format)\n",
    "    - AVG_DAYS (int): the number of days to average the stock data over\n",
    "    - TRIGRAMS (bool): whether to include trigram features in the model\n",
    "    - ADDITIONAL (list): a list of additional features to include in the model\n",
    "    - CLASSES (int): the number of classes for the classification problem (2 for binary classification, more than 2 for multiclass)\n",
    "    - symbols (list): a list of stock symbols to include in the simulation\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "\n",
    "    Saves the results of the simulation to a CSV file with a unique ID based on the simulation parameters.\n",
    "\n",
    "    Example:\n",
    "    run_simulation(10, \"2015-01-01\", \"2022-01-01\", 30, True, [\"rsi\", \"macd\"], 2, [\"AAPL\", \"GOOGL\", \"TSLA\", \"MSFT\", \"AMZN\"])\n",
    "    \"\"\"\n",
    "   \n",
    "        scores = pd.DataFrame(columns=[\"ticker\", \"svm_acc\", \"svm_prec\", \"svm_recall\", \"svm_f1\",\n",
    "                               \"knn_acc\", \"knn_prec\", \"knn_recall\", \"knn_f1\",\n",
    "                               \"rf_acc\", \"rf_prec\", \"rf_recall\", \"rf_f1\",\n",
    "                               \"gb_acc\", \"gb_prec\", \"gb_recall\", \"gb_f1\"])\n",
    "\n",
    "        \n",
    "        TEST_ID = [\"N\", str(N), \"_\",  START_TIME[2:4], \"-\",\n",
    "               END_TIME[2:4], \"CL\", str(CLASSES), \"(\", \"\".join(ADDITIONAL), \")\", \"D\", str(AVG_DAYS)]\n",
    "\n",
    "        if CUSTOM == True:\n",
    "            TEST_ID.append(\"_C\")\n",
    "        if TRIGRAMS == True:\n",
    "            TEST_ID.append(\"_T\")\n",
    "        TEST_ID = \"\".join(TEST_ID)\n",
    "        print(TEST_ID)\n",
    "        if CLASSES > 2:\n",
    "            average = \"weighted\"\n",
    "        else:\n",
    "            average = \"binary\"\n",
    "        \n",
    "        prob_tickers = []\n",
    "        models = []\n",
    "        No_POS = 0\n",
    "        No_NEG = 0\n",
    "        for i,f in enumerate(symbols[:N]):\n",
    "            \n",
    "            print(f)\n",
    "            print(f\"{i+1} out of {N} \")\n",
    "\n",
    "            try:\n",
    "                if f+\".csv\" not in os.listdir(\"Lin_et_al_2021//data//stocks//\"):\n",
    "                    \n",
    "                    df = yf.download(f, start=START_TIME, end=END_TIME)\n",
    "                    df.reset_index(inplace=True)\n",
    "                    df = format_data(df, start_time=START_TIME,\n",
    "                                    end_time=END_TIME, avg_days=AVG_DAYS,\n",
    "                                    trigrams=TRIGRAMS, additional=ADDITIONAL)\n",
    "                    \n",
    "                    df.to_csv(\"Lin_et_al_2021//data//stocks//\"+f+\".csv\")\n",
    "                else:\n",
    "                    df = pd.read_csv(\"Lin_et_al_2021//data//stocks//\"+f+\".csv\",index_col=0)\n",
    "                models, X_test, y_test = fit_models(df, models, classes=CLASSES,fit=False) \n",
    "                \n",
    "                if CLASSES == 2:\n",
    "                    No_POS += Counter(y_test)[0]\n",
    "                    No_NEG += Counter(y_test)[1]\n",
    "                \n",
    "                score_df = score_predictions(models,f,X_test,y_test,average)\n",
    "                scores = pd.concat([scores, score_df], ignore_index=True)\n",
    "                scores.to_csv(f\"Lin_et_al_2021//ensemble_results//{TEST_ID}.csv\")\n",
    "            except Exception as e:\n",
    "                print(str(e))\n",
    "                prob_tickers.append(f)\n",
    "\n",
    "            i += 1\n",
    "        print(No_POS)\n",
    "        print(No_NEG)\n",
    "        print(prob_tickers)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dfe3c5622ec02a0a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
